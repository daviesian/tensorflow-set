{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "from IPython.display import display\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import random\n",
    "from itertools import combinations\n",
    "import anvil.server\n",
    "import anvil.media\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    \n",
    "        \n",
    "colour_model = tf.keras.models.load_model(\"models/colour\")\n",
    "shape_model =  tf.keras.models.load_model(\"models/shape\")\n",
    "fill_model = tf.keras.models.load_model(\"models/fill\")\n",
    "number_model =  tf.keras.models.load_model(\"models/number\")\n",
    "\n",
    "vocab_colour = sorted([\"red\", \"green\", \"blue\"])\n",
    "vocab_shape = sorted([\"oval\", \"diamond\", \"squiggle\"])\n",
    "vocab_number = sorted([1,2,3])\n",
    "vocab_fill = sorted([\"filled\", \"open\", \"shaded\"])\n",
    "    \n",
    "def show(imgs):\n",
    "    for im in imgs:\n",
    "        #im = cv.cvtColor(im, cv.COLOR_BGR2RGB)\n",
    "        im = Image.fromarray(im)\n",
    "        im.thumbnail((400,400))\n",
    "        display(im)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to wss://anvil.works/uplink\n",
      "Anvil websocket open\n",
      "Connected to \"Default environment (dev)\" as SERVER\n"
     ]
    }
   ],
   "source": [
    "# https://anvil.works/build#app:SH7F4TDWQQUSHC7F\n",
    "\n",
    "anvil.server.connect(\"RWL6DCXP5PA5JSHIYP55ZV34-SH7F4TDWQQUSHC7F\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_imgs = [cv.cvtColor(cv.imread(x), cv.COLOR_BGR2RGB) for x in [f\"photos/{f}\" for f in os.listdir(\"photos\")]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilities\n",
    "\n",
    "def resize(img, size):\n",
    "    scale = size / max(img.shape)\n",
    "    \n",
    "    # cv.resize seems to need a destination image, and also returns a value. Weird.\n",
    "    x = img.copy()\n",
    "    x = cv.resize(x, (0,0), x, scale, scale, cv.INTER_AREA)\n",
    "    return x, scale\n",
    "\n",
    "def threshold(img):\n",
    "    gray = cv.cvtColor(img,cv.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # https://docs.opencv.org/master/d7/d4d/tutorial_py_thresholding.html\n",
    "    x = cv.adaptiveThreshold(gray,255,cv.ADAPTIVE_THRESH_GAUSSIAN_C, cv.THRESH_BINARY, int(gray.shape[1]/20)*2+1, 2)\n",
    "    \n",
    "    kernel = np.ones((3,3),np.uint8)\n",
    "    x = cv.erode(x, kernel, iterations=1)\n",
    "    \n",
    "    return x\n",
    "\n",
    "def contours(img):\n",
    "    # Nice contour docs: https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_imgproc/py_contours/py_contour_features/py_contour_features.html\n",
    "    # Find all contours, sorted by size\n",
    "    contours, hierarchy = cv.findContours(img, cv.RETR_EXTERNAL,cv.CHAIN_APPROX_TC89_KCOS)\n",
    "    contours.sort(key=cv.contourArea,reverse=True)\n",
    "    \n",
    "    # Simplify contours\n",
    "    simple_contours = [cv.approxPolyDP(c, 0.05*cv.arcLength(c, True),True) for c in contours]\n",
    "    \n",
    "    # Keep contours whose simple shape:\n",
    "    # - roughly matches the original shape, \n",
    "    # - is a rectangle, \n",
    "    # - has area > 500.\n",
    "    \n",
    "    simple_contours = [s for s,c in zip(simple_contours, contours) if cv.matchShapes(c,s,cv.CONTOURS_MATCH_I1,0) < 0.2 and len(s) == 4 and cv.contourArea(s) > 500]\n",
    "                \n",
    "    return simple_contours\n",
    "    \n",
    "def extract_contours(img, contours, w=300, h=None):\n",
    "    if h is None:\n",
    "        h = int(2 * (w / 3.0))\n",
    "    cards = []\n",
    "    target = np.float32([[0,0], [0,h], [w,h], [w,0]])\n",
    "    for s in contours:\n",
    "        # Roll contour until we're at the start of a short side.\n",
    "        s = np.roll(s, 2 * np.argmax([cv.arcLength(s[i:i+2], False) for i in range(3)]))\n",
    "        \n",
    "        s = np.float32(np.roll(s,2))\n",
    "        M = cv.getPerspectiveTransform(s, target)\n",
    "        persp = cv.warpPerspective(img, M, (w,h))\n",
    "        cards.append(persp)\n",
    "        \n",
    "    return cards\n",
    "\n",
    "    \n",
    "# Takes a cv Image and returns a list of card images\n",
    "\n",
    "def image_to_cards(img, verbose=True):\n",
    "    \n",
    "    # Resize image to ~400px for thresholding\n",
    "    small, scale = resize(img, 400)\n",
    "    \n",
    "    # Threshold image\n",
    "    bw = threshold(small)\n",
    "    \n",
    "    # Find contours and upscale back to original image size\n",
    "    card_contours = [np.int32(c / scale) for c in contours(bw)]\n",
    "    outlined = img.copy()\n",
    "    cv.drawContours(outlined, card_contours, -1, (255,255,0), 20)\n",
    "    \n",
    "    # Extract cards\n",
    "    cards = extract_contours(img, card_contours, 120)\n",
    "    \n",
    "    return bw, outlined, card_contours, cards\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyse_image(img):\n",
    "    bw, outlined, contours, cards = image_to_cards(img)\n",
    "    show([bw, outlined])\n",
    "    \n",
    "    cards_array = np.uint8(cards)\n",
    "\n",
    "    colour_scores = tf.nn.softmax(colour_model(cards_array))\n",
    "    shape_scores = tf.nn.softmax(shape_model(cards_array))\n",
    "    fill_scores = tf.nn.softmax(fill_model(cards_array))\n",
    "    number_scores = tf.nn.softmax(number_model(cards_array))\n",
    "    \n",
    "    colours = [vocab_colour[i] for i in tf.argmax(colour_scores, 1)]\n",
    "    shapes = [vocab_shape[i] for i in tf.argmax(shape_scores, 1)]\n",
    "    fills = [vocab_fill[i] for i in tf.argmax(fill_scores, 1)]\n",
    "    numbers = [vocab_number[i] for i in tf.argmax(number_scores, 1)]\n",
    "    \n",
    "    results = zip(\n",
    "        cards, contours,\n",
    "        colours, shapes, fills, numbers, \n",
    "        np.max(colour_scores,1), np.max(shape_scores,1), np.max(fill_scores,1), np.max(number_scores,1)\n",
    "    )\n",
    "    \n",
    "    return results\n",
    "    \n",
    "def print_results(results):\n",
    "    for card, contour, colour, shape, fill, number, colour_score, shape_score, fill_score, number_score in results:\n",
    "        show([card])\n",
    "        print(f\"{number} ({number_score:.1%})\")\n",
    "        print(f\"{fill} ({fill_score:.1%})\")\n",
    "        print(f\"{colour} ({colour_score:.1%})\")\n",
    "        print(f\"{shape} ({shape_score:.1%})\")\n",
    "        print(\"----------------\")\n",
    "        \n",
    "def highlight_set(img, card_set, set_index):\n",
    "    colors = [(255,255,0), (255,0,255), (0,255,255)]\n",
    "    w = img.shape[0]*0.02\n",
    "    print(img.shape)\n",
    "    cv.drawContours(img, [c[1] for c in card_set], -1, colors[set_index % len(colors)], int(w - set_index*0.45*w))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anvil websocket closed (code 1006, reason=Going away)\n",
      "Reconnecting Anvil Uplink...\n",
      "Connecting to wss://anvil.works/uplink\n",
      "Reconnection failed. Waiting 10 seconds, then retrying.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def find_sets_in_img(img):\n",
    "    results = analyse_image(img)\n",
    "    #print_results(results)\n",
    "\n",
    "    result_img = img.copy()\n",
    "    set_idx = 0\n",
    "    for cards in combinations(results, 3):\n",
    "\n",
    "        colours = [c[2] for c in cards]\n",
    "        shapes = [c[3] for c in cards]\n",
    "        fills = [c[4] for c in cards]\n",
    "        numbers = [c[5] for c in cards]\n",
    "\n",
    "        features = [colours, shapes, fills, numbers]\n",
    "        valid_set = True\n",
    "        for f in features:\n",
    "            valid_set = valid_set and (len(set(f)) == 3 or len(set(f)) == 1)\n",
    "\n",
    "        if valid_set:\n",
    "            highlight_set(result_img, cards, set_idx)\n",
    "            set_idx += 1\n",
    "            print(\"--- SET ---\")\n",
    "            print(colours, shapes, fills, numbers)\n",
    "            show([c[0] for c in cards])\n",
    "            \n",
    "    return result_img if set_idx > 0 else None\n",
    "\n",
    "@anvil.server.callable\n",
    "def find_sets(img_media):\n",
    "    img_data = img_media.get_bytes()\n",
    "    img = cv.cvtColor(cv.imdecode(np.frombuffer(img_data, np.uint8), cv.IMREAD_COLOR), cv.COLOR_BGR2RGB)\n",
    "    \n",
    "    result = find_sets_in_img(img)\n",
    "    \n",
    "    show([result])\n",
    "    \n",
    "    with anvil.media.TempFile() as file_name:\n",
    "        file_name += \".jpg\"\n",
    "        result_bgr = cv.cvtColor(result, cv.COLOR_RGB2BGR)\n",
    "        cv.imwrite(file_name,result_bgr)\n",
    "    \n",
    "        return anvil.media.from_file(file_name, \"image/jpeg\")\n",
    "\n",
    "#result_img = find_sets_in_img(sample_imgs[15])\n",
    "#show([result_img])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
